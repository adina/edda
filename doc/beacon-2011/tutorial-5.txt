==========
Tutorial 5
==========

OK, in this tutorial we're going to do some *really* useful stuff: dealing
with spreadsheets of information.

You might want to read through the following Software Carpentry lectures,
and/or brush up on dictionaries, lists and for loops first.  See:

 - SWC 4.0, `Python <http://software-carpentry.org/4_0/python/>`__
 - SWC 4.0, `Sets and Dictionaries <http://software-carpentry.org/4_0/setdict/>`__

There are also some more recent book chapters from Software Carpentry
that might be useful; see:

 - `Basic programming in Python <http://lyorn.idyll.org/~t/swc/book/python.html>`__
 - `Sets and Dictionaries <http://lyorn.idyll.org/~t/swc/book/setdict.html>`__

I strongly recommend referring back to these if you run into any trouble!

Spreadsheets and "Comma Separated Values"
=========================================

Most spreadsheet programs -- in particular, Excel -- store their data in
specialized formats that you're not every going to want to touch.  But all
spreadsheet programs are capable of importing and exporting their data
to and from a basic format, generally known as "CSV".  CSV stands for
"comma-separated values" and basically means that your data is in a format
that looks like this::

   value1a,value1b,value1c,value1d
   value2a,value2b,value2c,value2d

That is, your basic spreadsheet format, bereft of any special formatting
or font information or even formulas.  Each row contains a set of values,
of which there are usually the same number (i.e. it's a rectangular
spreadsheet).

You can get a *lot* of different data in this format -- for example,
many genome annotations come in a variant of this format called 'GFF',
or 'General Feature Format'.

So, one of the main tasks that faces you will be this: reading in data
files in the CSV format.  This is also known as *parsing*.

Conveniently, Python has a module that takes care of a lot of the ugly
details for you!

Getting started
---------------

OK, the two tasks ahead of us are these:

 - first, find a file with some data and *open it* for reading;
 - second, use the csv module to parse that file.

(You'll probably want to use IDLE or some other Python interface to run
the following commands, although they should work in Crunchy.)

Rather than dealing with local files, we're going to be daring and load
things in over the Web.  This simplifies my job of providing you the data,
and means that you don't have to worry about where the files are sitting on
your local hard drive.  We'll talk about file paths and locations for
dealing with local files -- but later.

There's a general concept in Python called 'file handles', which are
just variables representing files that are open for reading and/or
writing.  As I said above, we'll go over them more later, but the
important bit is that once you have a file handle you can *iterate* over it.

Try running the following bit of code::

   # import the module that deals with Web requests
   import urllib
   # line by line, print out the remote file
   for line in urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv'):
      print line

What you see is a line-by-line output of the contents of the file that
are at the Web address (a.k.a. 'URL') https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv.  Yes, Python is
contacting the remote computer, grabbing the file, and pulling down the
data line by line.  Pretty neat, eh?

What's even neater is that the csv module can parse CSV lines from *any
file handle*, so we can treat this remote data set as a source of CSV data::

   # import the two necessary modules
   import csv, urllib

   # point the variable 'fp' at the remote data:
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')

   # parse it with csv!
   for row in csv.reader(fp):
      print row

Look carefully at the output of this command, and compare it to the results
from the first command.  What's going on?

In the first set of commands, you were grabbing data from that remote
file line by line, and printing out each line.  In *this* set of commands,
you're asking the csv module to parse each line as a set of comma-separated
values -- and it's returning a list for each line, rather than a string!

What's neat about this is you can go through and grab individual columns
of data as you wish: for example, try running this::

   # import the two necessary modules
   import csv, urllib

   # point the variable 'fp' at the remote data:
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')

   # parse it with csv!
   for row in csv.reader(fp):
      print row[0], row[2]

Here you're grabbing columns 1 and 3 selectively.

This file, in case you're interested, is a list of teens, together with
their ages, favorite colors, and gender.  So what you did with that last
command is printed out names and their favorite color.

You can even do more complicated things like printing out only the
data from rows that satisfy certain conditions::

   # import the two necessary modules
   import csv, urllib

   # point the variable 'fp' at the remote data:
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')

   # parse it with csv!
   for row in csv.reader(fp):
      if row[3] == 'f':
         print row[2]

Here, you're printing out the favorite colors of all female students.

Right -- so now you know Python code that can grab spreadsheet data
from remote servers, parse it, and select interesting values.

As usual with programming, the power of this isn't confined to small examples,
as you'll see in the homework.

All of the examples above do a kind of "stream" processing -- you're processing
data as it comes in, examining it, and selecting out the bits that you care
about.  (It's called "stream processing" 'cause it's like you're watching
items of data float by on a stream, and picking the ones you want.)
This has the advantage of being really simple, but what if you want to
be able to look rows up later?  Then you need to be able to store items
somehow.

One way to store items taken from a CSV document would be to simply
store them in a list::

   # import the two necessary modules
   import csv, urllib

   # initialize an empty list
   datalist = []

   # point the variable 'fp' at the remote data:
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')

   # parse it with csv!
   for row in csv.reader(fp):
      datalist.append(row)

but this has a couple of disadvantages.  The main one is that if you want to
name and retrieve specific rows, you'll either have to know their position
in the list, OR you'll have to go through the entire list again.  And that's
slow!

So what about using a dictionary?

Saving and retrieving data in dictionaries
------------------------------------------

Let's look at the items in short.csv::

   time,15,blue,m

is the first line.  What if we want to be able to retrieve rows by the
values in the first line, i.e. the name?  We can easily use a
dictionary to do this::

   # import the two necessary modules
   import csv, urllib

   # initialize an empty dict
   datadict = {}

   # point the variable 'fp' at the remote data:
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')

   # parse it with csv!
   for row in csv.reader(fp):
      key = row[0]
      datadict[key] = row

Now we can ask 'what is the row of values associated with the name "diane"
in the first column' and get the answer easily::

   print datadict['diane']

Digression: iterating vs looking up
-----------------------------------

Why are we storing things in dictionaries instead of lists, anyway?

There are two complementary reasons.

The first and in some ways most important is that dictionaries let us
*name* things: storing and retrieving by a key is the same thing,
semantically, as naming something and referring to it by name.  So
using dictionaries is very natural and lets you write clear code.  Rather than
doing::

   for row in datalist:
      if row[0] == 'tim':
         print row

to retrieve the data associated with the name tim, we can just do::

   print datadict['tim']

This is much clearer, I think -- shorter, and more direct, and just
plain easier to read.

It's also *faster*.  When you store & look things up by name, Python
can do the lookups quite quickly.  This doesn't matter now with small
data sets that contain only a few dozen to a few hundred rows, but if
you have to look through a few thousand rows every time you want to
retrieve data, it's going to be very slow going.  Dictionaries solve
this problem by providing a really general interface to retrieving
things *fast* - as long as you can hang a unique key on data,
something like a name or a number, you can retrieve it quickly.

The *disadvantage* is that if you have multiple people named 'tim', then
you can only store one value associated with tim in the dictionary.  We'll
talk a bit more about this below.

Slightly more advanced CSV
--------------------------

You might be getting slightly annoyed by having to refer to column *numbers*
in each row, like row[0] in this example::

   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')
   for row in csv.reader(fp):
      if row[0] == 'tim':
         print row

Wouldn't it be nice if you could refer to columns by name?  Ahh, but
you can!  If you use 'csv.DictReader' instead of 'csv.reader', the
names of the columns will automatically be filled in from the first
row (the header row) that is reasonably common in these kinds of
files.  For example, I've provided you with a file,
'short-header.csv', that contains the same data in short.csv but with
a header line; if you use DictReader you can see now that each row has
become a dictionary with the keys 'name', 'age', 'color', and
'gender'. ::

   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short-headers.csv')
   for row in csv.DictReader(fp):
      if row['name'] == 'tim':
         print row

You can also do this for files without that first header row by
specifying the headers explicitly to DictReader::
 
   import csv, urllib

   datafile = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short.csv')
   csv_data = csv.DictReader(datafile, fieldnames=['name','age','color','gender'])

   for data in csvdata:
      print data['name'], data['color']

Inverting dictionaries
----------------------

Suppose we wanted to ask which people had a gender of 'm', and wanted
to be able to use a dictionary to retrieve it quickly?

Let's start by loading everything into 'datadict', as above::

   import csv, urllib
   datadict = {}
   fp = urllib.urlopen('https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/short-headers.csv')

   for row in csv.DictReader(fp):
      key = row['name']
      datadict[key] = row

OK, now all the data is in 'datadict'.  How can we get the names of 
everyone with the gender 'm'?

One *slow* way is to go through all of the names in the dictionary and
ask which ones have the gender 'm'::

   for name in datadict:
      row = datadict[name]
      if row['gender'] == 'm':
         print 'found a male:', name

How would we make this into a short lookup, rather than a long iteration?

Well, if you look at the contents of 'short.csv', you immediately run
into a problem: there are multiple people with the gender 'm'.  So you
can't just make a second dictionary keyed on that gender -- you'd only
store the last name you saw for 'm'!  For example::

   gender_dict = {}
   for name in datadict:
      row = datadict[name]
      gender = row['gender']
      gender_dict[gender] = name

gives you a dictionary that looks like this::

   { 'm' : 'ringo', 'f' : 'diane' }

that's correct as far as it goes but there are far more 'm' and 'f' in
the file!

What can you do about this??

OK, take a look at the following code::

   gender_dict = {}
   for name in datadict:
      row = datadict[name]
      gender = row['gender']

      # get a list of names with that gender already assigned; create a new
      # list if none seen yet.
      name_list = gender_dict.get(gender, [])

      # now, append the name to the list
      name_list.append(name)

      # ...and re-store it in the dictionary:
      gender_dict[gender] = name_list

What does this do?

Well, basically, it creates a dictionary 'gender_dict' that has, as keys,
genders - so, 'm' or 'f' -- and as values, *lists* of names.  So::

  gender_dict['m']

will return ::

  ['tim','john','ringo']

I should say that this looks a lot more complicated than it really is.
The key to reading code like this is to decompose it into simple operations
that you understand, and then try to put it back together in your head.
For example, in this case, you're:

 - getting the gender for each row
 - getting the value for that gender from the gender_dict.

Now, the value in this case should be a *list*, so you need to make sure
that if the gender doesn't exist in the gender_dict yet, you use a list.
In the above case, I use 'get' to return a list if there's nothing in
the dict.  This is equivalent in function to either this code::

   gender_dict = {}
   for name in datadict:
      row = datadict[name]
      gender = row['gender']

      # if this gender isn't in the gender_dict yet, add it as an empty list.
      if gender not in gender_dict:
         gender_dict[gender] = []

      # get a list of names with that gender already assigned
      name_list = gender_dict.get[gender]

      # now, append the name to the list
      name_list.append(name)

      # ...and re-store it in the dictionary:
      gender_dict[gender] = name_list

or this code::

   gender_dict = {}
   for gender in ['m', 'f']:
      gender_dict[gender] = []

   for name in datadict:
      row = datadict[name]
      gender = row['gender']

      # get a list of names with that gender
      name_list = gender_dict[gender]

      # now, append the name to the list
      name_list.append(name)

      # ...and re-store it in the dictionary:
      gender_dict[gender] = name_list

...although I don't know if that's any clearer in practice ;).

---

Digression: debugging stuff and grokking code with print
--------------------------------------------------------

We're getting into reasonably complicated code.  How can we figure out
what it is REALLY doing, in detail?

Consider the following modification to the code that saves names by
gender, in which we add print statements all over the place::

  gender_dict = {}
  for name in datadict:
      print 'NEW NAME:', name
      
      row = datadict[name]
      print 'row is:', row
      
      gender = row['gender']
      print 'gender is:', gender
  
      # get a list of names with that gender already assigned; create a new
      # list if none seen yet.
      name_list = gender_dict.get(gender, [])
      print 'name list currently is:', name_list
  
      # now, append the name to the list
      name_list.append(name)
      print 'appended', name
  
      # ...and re-store it in the dictionary:
      gender_dict[gender] = name_list
      print 'saved new name list:', name_list

What does this output when you run it? ::

  NEW NAME: jane
  row is: {'color': 'red', 'gender': 'f', 'age': '16', 'name': 'jane'}
  gender is: f
  name list currently is: []
  appended jane
  saved new name list: ['jane']
  NEW NAME: tim
  row is: {'color': 'blue', 'gender': 'm', 'age': '15', 'name': 'tim'}
  gender is: m
  name list currently is: []
  appended tim
  saved new name list: ['tim']
  NEW NAME: john
  row is: {'color': 'red', 'gender': 'm', 'age': '14', 'name': 'john'}
  gender is: m
  name list currently is: ['tim']
  appended john
  saved new name list: ['tim', 'john']
  NEW NAME: diane
  row is: {'color': 'green', 'gender': 'f', 'age': '14', 'name': 'diane'}
  gender is: f
  name list currently is: ['jane']
  appended diane
  saved new name list: ['jane', 'diane']
  NEW NAME: ringo
  row is: {'color': 'black', 'gender': 'm', 'age': '15', 'name': 'ringo'}
  gender is: m
  name list currently is: ['tim', 'john']
  appended ringo
  saved new name list: ['tim', 'john', 'ringo']

This is my favorite way to debug.  Basically, you can follow *everything*
that's going on, using this as a trace of what the program is doing line
by line.  You should look through this trace, make sure you understand
what each operation does, and then see if it fits YOUR expectations of
what should be going on.

For really complicated bits of code, I sometimes use a piece of paper
to keep track of things.  It's really the only way to make it clear,
sometimes.
  
Asking questions of data with functions
---------------------------------------

Suppose you want to retrieve a bunch of *different* data from a CSV file.

Also, once you've loaded the data once, you generally don't want to
load it again.

Take a look at @@@.  Here, I provide a bunch of functions that load in
the list of names and build a bunch of convenient dictionaries.

@@@ TODO.

---

Homework 5
----------

Using the following CSV file,

   https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/fishies.csv

write code to calculate answers to the following questions (also see HW 2 in
:doc:`tutorial-2`):

**HW 5.1**: the number of different types of fish in this list;

**HW 5.2**: the daily average number for each kind of fish (there are 365 days of fish eatin' in this list).

**HW 5.3**: the fat-weighted daily fish index, FI, for the entire
year.  (Salmon and ahi: 2.0; cod and sole, 0.5; the rest, 1.0.)

**HW 5.4**: the average number of *types* of fish per day.

**HW 5.5**: what days Penny ate a given fish.  (You can print the results out,
or put them in a list, or whatever; just write the appropriate for loop to print or build the list.)

(There's a shorter version of the file here:

   https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/fishies-short.csv

for testing purposes.)

Homework 6
----------

Add functions to load_fishies.py to *efficiently* return the list of
days on which a given type of fish was eaten by Penny.  (See:
https://raw.github.com/ctb/edda/master/doc/beacon-2011/tutorial5/load_fishies.py)

I suggest the following breakdown of the task:

 1) first, write a new function 'make_dates_dict' that takes in fish_d
 (as returned by load_csv) and builds a *new* dictionary: one where
 the keys are fish, and the values are lists of dates where that fish
 was eaten by Penny.
 
 2) second, write another new function, 'get_dates_by_fish', that takes
 in the dictionary returned by 'makes_dates_dict' and the name of some
 fish, and then returns the dates that that fish was eaten by Penny.
 If the fish doesn't appear in the CSV file return an empty list.

Here is a template::

   def make_dates_dict(fish_d):
      dates_d = {}
      # write code HERE to fill in dates_d
      return dates_d

   def get_dates_by_fish(dates_d, fish):
      dateslist = []
      # write code HERE to fill in dateslist
      return dateslist

.. Put all of these functions in a single file that you upload to github.

.. Write query functions:
..  - what fish did penny eat on day x?
.. - what days did penny eat a given fish?

.. print!!!
